---
title: Заметки по книге PostgreSQL 15 изнутри
---

## Несортировано и неинтересно.

- Параметры типа `max_mem` выставляются на соединение. Соединений может быть много. Выходит нужно считать `max_mem_server = max_mem * max_connections`?
- Есть не только кастомные функции (UDF), но и кастомные типы данных и кастомные индексы. Наверное прикольно, например, для IP адресов, хранимых в строке для челокоудобности, индекс на CIDR вкорячить.

## WAL

Никакой магии нет, есть вызов fsync при записи журнала с операциями на диск. Скорость досигается за счёт того, что последовательная потоковая (а не в случайное место на диске как в случае update) выполняется быстрее. Ну и затем фиксируется fsync, после чего можно уже считать транзакцию закоммиченной. Есть асинхронный режим, в котором пользователя обманывают - говорят что всё закоммитили, но где-то полсекунды всё будет в памяти, а затем walwriter запишет всё скопом. Оптимизация ценой надёжности. fsync работает пофайлово, т.е. вызов commit() в транзакции не вызовет синхронизацию ВООБЩЕ ВСЕГО БУФЕРА ВСЕХ ФАЙЛОВЫХ СИСТЕМ В СИНХРОННОМ РЕЖИМЕ и транзакция не зависнет в хлам. Но тут есть одно но - ОС, конечно скажет, fsync выполнен, т.к. он записывает буфер из памяти на диск. А у диска есть ещё свой буфер записи и при длительной потере питания он не факт что сохранится.

## Update 2023.02

Вместо курса взялся [читать книгу](https://mastodon.ml/@fflitclub/109619403525965319). 

## Аномалии и уровни изоляции

Собрался таки почитать ещё об аномалиях и уровнях изоляции в #PostgreSQL 15.

Разработка без защиты от missed update похожа на ситуацию, когда пишешь пост с мобилы и ожидаешь что приложение крашнется. До чего ж мы дожили – нельзя уже доверять полю ввода текста, страшно, что оно пропадёт.

<details>
<summary>Оффтоп о редактировании Markdown</summary>
И ладно бы в вебе или на мобилке, так ведь даже модным #markdown-редакторам в #flatpak доверять не приходится. Но у них хоть сохранение есть на относительно надёжное хранилище по хоткею. Тащить ноут в кресло к читалке неудобно, но заметки в онгоуинге делать хочется. Но на мобиле печатать неудобно, планшет просто отбитый, а сидеть на стуле за ноутом ещё неудобнее.

Мне нравится редактор Apostrophe, но я не люблю начинать писать статьи не из консоли. Этот блог - git-репа, в ней есть специальный примитивный баш-скрипт, который создаёт файл из шаблона, подставляет нужную дату, название итд. И я не понимаю как понять какой командой запускать Apostrophe, сидящий во флатпаке, из консоли, пробовал "отревёрсить" найдя команду в ps aux | grep, но не помогло, "показать подробности" с док-панели ведёт в магазин приложений, а не показывает команду, которой он запускается, читать документацию впадлу, а ползать во всплывашке по файлового менеджера - больно.
</details>

### Сериализация

Я таки понял что такое ошибки сериализации спустя много лет после первой встречи с ними, что от них никуда не деться, если денежки считаешь, а всё что остаётся при её получении – делать повторную попытку. Вспомнил ситуацию "и хочется и колется" – `SERIALIZABLE`, позволял не изъёбываться с защитой от аномалий на уровне приложения, но делал БД бутылочным горлышком, выжирая ресурсы сервера. Surprise motherfucker, но на репликах `SERIALIZABLE` не работает. Понятно почему, но не понятно, что делать - хочешь консистентно считать бабки – теряй доступность, навернулся мастер - иди чини. Ох уж старая добрая **CAP**.

Мне нравится, что в PostgreSQL уровень изоляции можно задать на уровне отдельной транзакции - маловажную в вопросе консистентности статистику собирать можно на уровне READ COMMITTED. В **Firebird** это вроде только глобально рулилось. Странно, но не понимаю, почему `BEGIN ISOLATION LEVEL SERIALIZABLE READ ONLY DEFFERABLE` нельзя подразумевать, анализируя текст одиночного SQL-запроса, автоматически обёртываемого в транзакцию, на клиенте, до отправки запроса.

### Ошибки

Нравится как PostgreSQL отдаёт при ошибке ERROR, DETAIL и HINT. Я недавно похожее поведение делал, чтобы в интерфейсе ошибки писали:

- **что** и **где** произошло - высокоуровневое описание что приложение делало, но обломалось;
- **почему** - технические детали;
- **что делать** - подсказка живому человеку, нетехнарю.

Теперь в логи бегать не надо лишний раз, да и пользователю к программистам тоже лишний раз можно не обращаться.

### Слои абстракции

Вспомнил, что клиенты часто просили добавить поддержку Oracle или PostgreSQL в роли СУБД. Типа Firebird отстой, но понимания, что другие СУБД дадут по сравнению с Firebird в 90% случаев не было, как и желания платить за их добавление и поддержку. Просто это было модно. Сейчас они бы грустили с лицензиями на Oracle.

Смена СУБД весёлая тема, за десять лет помню только как с MySQL на PostgreSQL переезжали, но причин не помню - мб MySQL взяли чисто для прототипирования, а для тестов SQLite использовали, чтобы не тащить docker и не возиться с конфигурированием сетевого доступа. Программисты абстрагируются от СУБД, чтобы переезжать по щелчку, но переезды происходят редко, а неудобства и без абстракций на уровне кода хватает.

Наличие слоя абстракции соблазняет отложить принятие архитектурного решения о выборе СУБД, но неопределённость в важных нюансах - снежок, который катится по склону горы, превращаясь в лавину.

## Vacuum

Сильно хихикаю с формулировки – 1 are dead but not yet removable. Тяжело от трупов избавляться, даже если это БД.

Сканирование таблиц при очистке похоже на венчурное инвестирование. Продолжается либо пока не закончится таблица (прибыльные идеи), либо память (бабло), выделенная под обслуживание.

Autovacuum похож на попытку усидеть на двух стульях - не пылесосить таблицу _постоянно и напрасно_, но и не пылесосить _редко настолько, что придется в несколько проходов это делать_.

``` sql
=> VACUUM VERBOSE tfreeze;
INFO: aggressively vacuuming "internals.public.tfreeze"
```

А мы с PostgreSQL похожи...

По мере чтения происходит disenchantment – никакой магии и волшебства в постгресе нет. Скорее много костылей для того, чтобы сглаживать пиквые нагрузки за счёт откладывания на потом. И местами костыли, чтобы не делать лишней работы. Теперь мне не так страшно такие костыли и на работе мутить (хотя я и раньше не боялся).

Сейчас читаю про заморозку, которая помечает строки созданные транзакцией, ушедшей за горизонт событий особым образом так, чтобы их номер (игнорировался и мог быть переиспользован) всегда считался в прошлом, чтобы на номер транзакции можно было полагаться при сравнении транзакций, даже при условии переполнения 32-битного счётчика транзакций. 64-битный юзать стрёмно так как заголовок верси строки в базе содержит 2 версии (min, max) лишних 8 байт выйдет.

Читаю про аварийную заморозку. Там упоминают что есть кейсы, когда VACUUM вырубают. Но зачем? В каком кейсе это было бы актуально? При высокой нагрузке на чтение из readonly БД со статичными данными и в очень ограниченном пространстве памяти? Зачем?

## Многоверсионность

PostgreSQL во многом похож на прокрастинатора - многоверсионность можно описать "пофигу, просто запишем строку целиком ещё раз, а потом кто-нибудь (возможно я сам) разберётся". Если простыми словами, подводные камни в следующем - UPDATE под капотом работает как DELETE + INSERT, а SELECT может вызвать дисковую запись. Первое пытаются регулировать внутристраничной очисткой (см. fillfactor).

## Буферный кэш

Забавно то, что есть прямо напрашивающееся расширение `pg_buffercache` - оно позволяет просматривать кэш в виде таблицы, которой тот по сути и является. Кэш состоит из заголовка и копии страницы. В заголовке есть много флагов. По сути это всё можно считать полями таблицы, а саму страницу - BLOB-полем.

Вытеснение из буфера через clock sweep прикольно сделали, нраица, звучит похоже на мобилизацию ЕВПОЧЯ.

А ещё, кажется я в проде нещадно ломаю нам буферный кэш за счёт массивных INSERT и UPDATE, причём параллельно с нескольких реплик, предназначенных для отложенных и периодических жирных задачек, которые занимаются перегоном данных.

## Попутные мысли

Интересно, насколько сложно написать расширение поверх PostgreSQL, которое будет на 53 порту слушать и на DNS запросы отвечать. По сути DNS-сервера сводятся либо к построению собственной базы данных в памяти, либо подключению внешней, опционально проксируя часть запросов к другим серверам. И я подумал, а что если начать с другой стороны? Так не придётся гонять данные туда-сюда.
